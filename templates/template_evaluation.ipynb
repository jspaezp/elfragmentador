{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,argparse\n",
    "from IPython.display import HTML\n",
    "\n",
    "CONFIG_FILE = '.config_ipynb'\n",
    "\n",
    "if os.path.isfile(CONFIG_FILE):\n",
    "    print(\"Reading config file\")\n",
    "    with open(CONFIG_FILE) as f:\n",
    "        sys.argv = f.read().split()\n",
    "else:\n",
    "    print(\"No config file found, using default values\")\n",
    "    sys.argv = ['evaluate.py', '--data_csv', \"~/git/ppptr/combined_holdout.csv\", '--checkpoint', 'prosit_transformer-val_loss=0.334872_epoch=005.ckpt']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--data_csv\", type=str, help=\"CSV file containing Sequences, Encodings, mIRT, SpectraEncoding, Charge\")\n",
    "parser.add_argument(\"--checkpoint\", type=str, help=\"Checkpoint file to use for evaluation\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "#args = parser.parse_args()\n",
    "\n",
    "dict_args = vars(args)\n",
    "\n",
    "\"\"\"\n",
    "dict_args = {\n",
    "    'data_csv': \"~/git/ppptr/combined_holdout.csv\",\n",
    "    \"checkpoint\": '~/Downloads/prosit_transformer-epoch=20-step=14174.ckpt'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "print(dict_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transprosit import model\n",
    "from transprosit.datamodules import PeptideDataset\n",
    "from transprosit import spectra\n",
    "from transprosit import encoding_decoding\n",
    "from transprosit import constants\n",
    "\n",
    "pl.seed_everything(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dataloader/dataset\n",
    "mod = model.PepTransformerModel.load_from_checkpoint(dict_args['checkpoint'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"input_csv\"\n",
    "df = pd.read_csv(dict_args['data_csv'])\n",
    "print(df)\n",
    "\n",
    "# Uncomment this line on the next release ...\n",
    "# df = df[[len(eval(x)) == constants.MAX_SEQUENCE for x in df[\"SequenceEncoding\"]]].copy().reset_index()\n",
    "df = df[[len(eval(x)) == 25 for x in df[\"SequenceEncoding\"]]].copy().reset_index()\n",
    "# Note that the input sequence does not really have to be fixed\n",
    "\n",
    "# Subsample input dataframe to 2k observations, or less....\n",
    "df = df.loc[sample(list(df.index), min(500, len(df)))].copy().reset_index()\n",
    "\n",
    "# Generate a dataloader to \n",
    "ds = PeptideDataset(df)\n",
    "dl = DataLoader(ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "out_yhat_irts = []\n",
    "in_yhat_irts = []\n",
    "out_yhat_spectra = []\n",
    "in_yhat_spectra = []\n",
    "in_charges = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dl:\n",
    "        encoded_sequence, charge, encoded_spectra, norm_irt = batch\n",
    "        in_charges.append(charge)\n",
    "        in_yhat_irts.append(norm_irt)\n",
    "        in_yhat_spectra.append(encoded_spectra)\n",
    "\n",
    "        yhat_irt, yhat_spectra = mod(encoded_sequence, charge)\n",
    "        out_yhat_irts.append(yhat_irt)\n",
    "        out_yhat_spectra.append(yhat_spectra)\n",
    "        \n",
    "out_yhat_irts = torch.cat(out_yhat_irts)\n",
    "in_yhat_irts = torch.cat(in_yhat_irts)\n",
    "\n",
    "out_yhat_spectra = torch.cat(out_yhat_spectra)\n",
    "out_yhat_spectra[out_yhat_spectra < 0] = 0\n",
    "out_yhat_spectra = (out_yhat_spectra.T * (1 / out_yhat_spectra.max(axis = 1).values)).T\n",
    "\n",
    "in_yhat_spectra = torch.cat(in_yhat_spectra)\n",
    "in_yhat_spectra[in_yhat_spectra < 0] = 0\n",
    "in_yhat_spectra = (in_yhat_spectra.T * (1 / in_yhat_spectra.max(axis = 1).values)).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visialize the comparisson of predictions and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(out_yhat_irts, in_yhat_irts, marker = \".\", alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(in_yhat_spectra.flatten(), out_yhat_spectra.flatten(), marker = \".\", alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.nn.PairwiseDistance(2, keepdim=True)\n",
    "plt.hist(dist(in_yhat_spectra, out_yhat_spectra).flatten().numpy(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(200):\n",
    "    predicted = encoding_decoding.decode_fragment_tensor(df[\"Sequences\"][i], out_yhat_spectra[i,:])\n",
    "    ground_truth = encoding_decoding.decode_fragment_tensor(df[\"Sequences\"][i], in_yhat_spectra[i,:])\n",
    "\n",
    "    plt.title(f\"{df['Sequences'][i]}, {df['Charges'][i]}\")\n",
    "    plt.vlines(0, -1, 1, color = \"gray\")\n",
    "\n",
    "    plt.vlines(predicted['Mass'], 0, predicted['Intensity'], color = \"blue\")\n",
    "    plt.vlines(ground_truth['Mass'], 0, -ground_truth['Intensity'], color=\"red\")\n",
    "    plt.axhline(0, color='black')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize embeddings for the aminoacids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mod.encoder.aa_encoder.weight.data, aspect = \"auto\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAS = list(constants.ALPHABET.keys())\n",
    "AA_NAMES = [\"#\"] + AAS\n",
    "\n",
    "aa_weight_df = pd.DataFrame(mod.encoder.aa_encoder.weight.data.numpy(), index = AA_NAMES)\n",
    "aa_weights = aa_weight_df.loc[[x for x in AAS]]\n",
    "p = sns.clustermap(\n",
    "    aa_weights, z_score = None, col_cluster=True,\n",
    "    cmap = 'viridis',\n",
    "    figsize = (5,5), dendrogram_ratio = (0.1, 0.1),\n",
    "    method = \"ward\", vmin=-0.05, vmax=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between each sample\n",
    "Z = linkage(aa_weights, 'ward')\n",
    " \n",
    "# Make the dendro\n",
    "plt.subplots(figsize=(3, 6))\n",
    "dendrogram(Z, labels=aa_weights.index, orientation=\"left\", color_threshold=1.8, above_threshold_color='grey', distance_sort='ascending')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(aa_weights.values.T).T\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "pca_weights = pca.fit_transform(x)\n",
    "print(pca_weights.shape)\n",
    "\n",
    "plt.subplots(figsize=(5, 5))\n",
    "plt.scatter(pca_weights[...,0], pca_weights[...,1])\n",
    "for i in range(0, len(aa_weights)):\n",
    "    plt.text(pca_weights[i,0] + 0.5, pca_weights[i,1], aa_weights.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the encodings of the ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_weight_df = pd.DataFrame(mod.decoder.trans_decoder_embedding.weight.data.numpy(), index = constants.FRAG_EMBEDING_LABELS)\n",
    "frag_weights = frag_weight_df.loc[[x for x in constants.FRAG_EMBEDING_LABELS]]\n",
    "p = sns.clustermap(\n",
    "    frag_weights, z_score = None, col_cluster=True,\n",
    "    cmap = 'viridis',\n",
    "    figsize = (10,10), dendrogram_ratio = (0.1, 0.1),\n",
    "    method = \"ward\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between each sample\n",
    "Z = linkage(frag_weights, 'ward')\n",
    " \n",
    "# Make the dendro\n",
    "plt.subplots(figsize=(5, 34))\n",
    "dendrogram(Z, labels=frag_weights.index, orientation=\"left\", color_threshold=40, above_threshold_color='grey', distance_sort='ascending', leaf_font_size = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visializing activations on different layers of the encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_visualisation = {}\n",
    "decoder_visualisation = {}\n",
    "\n",
    "def make_hook(target):\n",
    "    def hook_fn(m, i, o):\n",
    "        target[m] = o\n",
    "    \n",
    "    return hook_fn\n",
    "\n",
    "handles = []\n",
    "encoder_hook = make_hook(encoder_visualisation)\n",
    "for layer in range(0, len(mod.encoder.transformer_encoder.layers)):\n",
    "    print(f\"Adding hook to encoder layer: {layer}\")\n",
    "    handle = mod.encoder.transformer_encoder.layers[layer].self_attn.register_forward_hook(encoder_hook)\n",
    "    handles.append(handles)\n",
    "\n",
    "decoder_hook = make_hook(decoder_visualisation)\n",
    "for layer in range(0, len(mod.decoder.trans_decoder.layers)):\n",
    "    print(f\"Adding hook to decoder layer: {layer}\")\n",
    "    handle = mod.decoder.trans_decoder.layers[layer].self_attn.register_forward_hook(decoder_hook)\n",
    "    handles.append(handles)\n",
    "\n",
    "\"\"\"\n",
    "# Use this to remove the handles\n",
    "for h in handles:\n",
    "    h.remove()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num, batch in enumerate(dl):\n",
    "    if batch_num == 25:\n",
    "        encoded_sequence, charge, encoded_spectra, norm_irt = batch\n",
    "        break\n",
    "\n",
    "yhat_irt, yhat_spectra = mod(encoded_sequence, charge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the activation on the transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(encoder_visualisation.values())[0][1].shape # shape is [batch, 25, 25]\n",
    "\n",
    "sequences = []\n",
    "last_seq = \"\"\n",
    "for pep in range(10):\n",
    "    df_position = 32*batch_num + pep\n",
    "    sequence = df['Sequences'][df_position]\n",
    "    if sequence == last_seq:\n",
    "        continue\n",
    "    \n",
    "    last_seq = sequence\n",
    "    \n",
    "    fig, axs = plt.subplots(1,4, figsize=(25, 6))\n",
    "\n",
    "    print(sequence)\n",
    "    print(len(sequence))\n",
    "    # print(encoded_sequence[pep])\n",
    "    recoded_seq = \"\".join([([\"_\"] + AAS)[i] for i in encoded_sequence[pep]])\n",
    "    print(recoded_seq)\n",
    "    sequences.append(recoded_seq)\n",
    "\n",
    "    fig.suptitle(sequence + \" \" + str(df['Charges'][df_position]) + \"+\")\n",
    "\n",
    "    for i in range(4):\n",
    "        axs[i].set_title(f'Layer {i}')\n",
    "        axs[i].imshow(list(encoder_visualisation.values())[i][1][pep,:,:].detach().numpy()[0:len(sequence),0:len(sequence)], vmin = 0, vmax = 0.2)\n",
    "        axs[i].set_xticks(np.arange(len(sequence)))\n",
    "        axs[i].set_yticks(np.arange(len(sequence)))\n",
    "        axs[i].set_xticklabels([x for x in sequence])\n",
    "        axs[i].set_yticklabels([x for x in sequence])\n",
    "        \n",
    "        for ii in range(len(sequence)):\n",
    "            for j in range(len(sequence)):\n",
    "                if ii != j:\n",
    "                    continue\n",
    "                axs[i].text(j, ii, \"O\", ha=\"center\", va=\"center\", color=\"w\")\n",
    "        \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the activation on the transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[1].shape for x in list(decoder_visualisation.values())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ">>> [ [x[0].shape, x[1].shape] for x in list(decoder_visualisation.values()) ]\n",
    "\n",
    "[[torch.Size([150, 32, 516]), torch.Size([32, 150, 150])],\n",
    " [torch.Size([150, 32, 516]), torch.Size([32, 150, 150])],\n",
    " [torch.Size([150, 32, 516]), torch.Size([32, 150, 150])],\n",
    " [torch.Size([150, 32, 516]), torch.Size([32, 150, 150])]]\n",
    "\n",
    ">>> # would be all the LAYER ACTIVATIONS\n",
    ">>> activations_averages = [x[1] for x in list(decoder_visualisation.values())] \n",
    "\n",
    ">>> # would be all the SELF ATTENTION AVERAGES\n",
    ">>> self_attn_averages = [x[1] for x in list(decoder_visualisation.values())] \n",
    "\n",
    ">>> # would give a list of the self attention layers for the first peptide in the batch.\n",
    ">>> [x[0, ...] for x in self_attn_averages] \n",
    "...\n",
    "\n",
    ">>> [x[0, ...].shape for x in self_attn_averages] \n",
    "[torch.Size([150, 150]),\n",
    " torch.Size([150, 150]),\n",
    " torch.Size([150, 150]),\n",
    " torch.Size([150, 150])]\n",
    "\n",
    "\n",
    "Each attention head returns\n",
    "\n",
    "Outputs:\n",
    "        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
    "          E is the embedding dimension.\n",
    "        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n",
    "          L is the target sequence length, S is the source sequence length.\n",
    "\n",
    "> Actual attention output\n",
    "attn_output\n",
    "> Average self attention\n",
    "attn_output_weights.sum(dim=1) / num_heads\n",
    "\n",
    "here, N = 32; E=512, L=150, S=150\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "sequences = []\n",
    "last_seq = \"\"\n",
    "labs = constants.FRAG_EMBEDING_LABELS\n",
    "\n",
    "self_attn_averages = [x[1] for x in list(decoder_visualisation.values())] \n",
    "\n",
    "for pep in range(10):\n",
    "    df_position = 32*batch_num + pep\n",
    "    sequence = df['Sequences'][df_position]\n",
    "    if sequence == last_seq:\n",
    "        continue\n",
    "    \n",
    "    last_seq = sequence\n",
    "    fig, axs = plt.subplots(2,5, figsize=(25, 10))\n",
    "\n",
    "    print(sequence)\n",
    "    print(len(sequence))\n",
    "    # print(encoded_sequence[pep])\n",
    "    recoded_seq = \"\".join([([\"_\"] + AAS)[i] for i in encoded_sequence[pep]])\n",
    "    print(recoded_seq)\n",
    "    sequences.append(recoded_seq)\n",
    "\n",
    "    fig.suptitle(sequence + \" \" + str(df['Charges'][df_position]) + \"+\")\n",
    "\n",
    "    spec = eval(df['SpectraEncoding'][df_position])\n",
    "    indices = [x for x in range(len(spec))]\n",
    "\n",
    "    axs[0,4].vlines(x = indices, ymin=[0 for _ in range(len(indices))], ymax=spec, color=\"black\")\n",
    "    axs[0,4].set(yticklabels=[])\n",
    "    axs[0,4].tick_params(left=False)\n",
    "    axs[0,4].set_title(f'Encoded Ground Truth Spectrum')\n",
    "    \n",
    "    for ind, inten in zip(indices, spec):\n",
    "        if inten < 0.1:\n",
    "            continue\n",
    "        axs[0,4].text(x = ind + 5, y = inten - 0.01, s = labs[ind], color = \"blue\")\n",
    "\n",
    "\n",
    "    peptide_self_attn_avgs = [x[pep, ...] for x in self_attn_averages] \n",
    "    \n",
    "    for i in range(4):\n",
    "        axs[0,i].set_title(f'Layer {i}')\n",
    "        axs[0,i].imshow(peptide_self_attn_avgs[i].detach().numpy(), vmin = 0., vmax = 0.03)\n",
    "        \n",
    "        out_labs = []\n",
    "        vals = []\n",
    "        act_vals = peptide_self_attn_avgs[i].detach().numpy()\n",
    "\n",
    "        for xind in range(constants.NUM_FRAG_EMBEDINGS):\n",
    "            for yind in range(constants.NUM_FRAG_EMBEDINGS):\n",
    "                if xind == yind:\n",
    "                    continue\n",
    "                vals.append(act_vals[xind, yind])\n",
    "                out_labs.append(f\"{labs[xind] : <6}\"+f\"{labs[yind] : >6}\")\n",
    "\n",
    "        interaction_df = pd.DataFrame({'Interaction': out_labs, 'Value': vals})\n",
    "\n",
    "        ordered_df = interaction_df.sort_values(by='Value')\n",
    "        plotting_df = pd.concat([ordered_df[:5], ordered_df[-15:]]).copy()\n",
    "        my_range=range(1,len(plotting_df.index)+1)\n",
    "\n",
    "        # Vertical lollipop chart.\n",
    "        axs[1,i].hlines(y=my_range, xmin=0, xmax=plotting_df['Value'], color='black')\n",
    "        axs[1,i].set_yticks(my_range)\n",
    "        axs[1,i].set_yticklabels(plotting_df['Interaction'])\n",
    "        axs[1,i].plot(plotting_df['Value'], my_range, \"D\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
